#!/usr/bin/env python

from __future__ import print_function
import click
import click_log
import yaml
import os
from cmsl1t.config import ConfigParser, get_unique_out_dir
import htcondor
import sys
import math
from textwrap import dedent
import logging
import subprocess
import pandas as pd
logger = logging.getLogger(__name__)
click_log.basic_config(logger)

JOB_INFO = pd.DataFrame(
    columns=['local_id', 'batch_id', 'config_file', 'output_folder',
             'stderr_log', 'stdout_log', 'status', 'batch']
)


class cmsl1t_batch_job_htcondor(object):
    run_script_name = "run_script.sh"

    def __init__(self, batch_directory, debug):
        self.debug = debug
        setup_script = os.path.join(
            os.environ["PROJECT_ROOT"], "bin", "env.sh")

        run_script_contents = dedent("""\
        #! /bin/bash
        source {setup_script}
        cmsl1t $@
        """).format(setup_script=setup_script)

        self.run_script = os.path.realpath(
            os.path.join(batch_directory, self.run_script_name))
        with open(self.run_script, "w") as run_script:
            run_script.write(run_script_contents)
        os.chmod(self.run_script, 0777)

    def submit(self, config_files):
        global JOB_INFO
        logger.info("Will submit %d jobs" % len(config_files))
        schedd = htcondor.Schedd()
        results = []
        for local_id, config_file in enumerate(config_files):
            with schedd.transaction() as txn:
                cfg = os.path.realpath(config_file)
                config = ConfigParser()
                with open(config_file) as f:
                    config.read(f)
                output_folder = config.config['output']['folder']
                error_log = os.path.join(output_folder, 'error.log')
                out_log = os.path.join(output_folder, 'out.log')

                job_cfg = dict(
                    executable=self.run_script_name,
                    arguments="-c {}".format(cfg),
                    Err=error_log,
                    Out=out_log,
                )
                sub = htcondor.Submit(job_cfg)
                batch_id = sub.queue(txn)
                results.append(batch_id)
                JOB_INFO.loc[len(JOB_INFO)] = [
                    local_id, batch_id, config_file, output_folder, error_log,
                    out_log, 'SUBMITTED', 'htcondor']
        logger.info(dedent("""\
        Jobs should be running on htcondor now.  To monitor their progress use:

            condor_q $USER """))

        return results


class cmsl1t_batch_job_bsub(object):
    run_script_name = "run_script.sh"

    def __init__(self, batch_directory, debug):
        self.batch_directory = batch_directory
        self.debug = debug
        setup_script = os.path.join(
            os.environ["PROJECT_ROOT"], "bin", "env.sh")

        run_script_contents = dedent("""\
        #! /bin/bash
        pushd {project_root}
        source {setup_script}
        cmsl1t -c "$1"
        popd
        """).format(project_root=os.environ["PROJECT_ROOT"], setup_script=setup_script)

        self.run_script = os.path.realpath(
            os.path.join(batch_directory, self.run_script_name))
        with open(self.run_script, "w") as run_script:
            run_script.write(run_script_contents)
        os.chmod(self.run_script, 0777)

    def submit(self, config_files):
        n_cfgs = str(len(config_files))
        logger.info("Will submit %s jobs using bsub" % n_cfgs)

        job_group = "/CMS-L1T--"
        directory_name = os.path.basename(
            os.path.dirname(self.batch_directory))
        job_group += directory_name.replace("/", "--")

        results = []
        for i, cfg in enumerate(config_files):
            logger.info("submitting: " + cfg)
            results.append(self._submit_one(cfg, i, group=job_group))

        logger.info(
            "    Check job status using:\n\n         bjobs -g {group}".format(group=job_group))
        return results

    def _submit_one(self, config_file, local_id, group=None):
        global JOB_INFO
        config = ConfigParser()
        with open(config_file) as f:
            config.read(f)
        output_folder = config.config['output']['folder']
        error_log = os.path.join(output_folder, 'error.log')
        out_log = os.path.join(output_folder, 'out.log')
        # create empty log files
        os.makedirs(output_folder)
        open(error_log, 'a').close()
        open(out_log, 'a').close()
        # Prepare the args
        args = ["bsub", "-q", "8nm"]
        if group:
            args += ["-g", group]
        args += ["-eo", error_log, "-oo", out_log]
        #args += ['-outdir', output_folder]
        command = ' '.join([self.run_script, config_file])
        args += [command]

        batch_id = 0
        try:
            batch_output = subprocess.check_output(args)
            batch_id = self.get_bsub_id(batch_output)
        except subprocess.CalledProcessError as e:
            msg = dedent("""\
                    Error submitting to bsub.
                    Output was:
                       {e.output}

                    Return code was:
                       {e.returncode}""")
            logger.error(msg.format(e=e))
            JOB_INFO.loc[len(JOB_INFO)] = [
                local_id, -1, config_file, output_folder, error_log,
                out_log, 'SUBMIT_FAILED', 'LSF']
            return False

        JOB_INFO.loc[len(JOB_INFO)] = [
            local_id, batch_id, config_file, output_folder, error_log,
            out_log, 'SUBMITTED', 'LSF']
        return True

    def get_bsub_id(self, bsub_output):
        tokens = bsub_output.split(' ')
        job_id = tokens[1]
        job_id = job_id.strip('<>')
        return int(job_id)


def prepare_input_file_groups(input_ntuples, files_per_job):
    file_lists = []
    current_list = []
    for infile in input_ntuples:
        if not infile.startswith("root:"):
            infile = os.path.realpath(infile)
        current_list.append(infile)

        # Is the current list full?
        if len(current_list) >= files_per_job:
            file_lists.append(current_list)
            current_list = []

    # Even if the last list had fewer files than needed, make sure to use this
    # too
    if current_list:
        file_lists.append(current_list)

    return file_lists


def create_info_file(batch_dir):
    global JOB_INFO
    JOB_INFO.to_csv(os.path.join(batch_dir, 'info.csv'))


@click.command()
@click.option('-c', '--config_file', help='YAML style config file', type=click.File(), required=True)
@click.option('-f', '--files-per-job', help='Give each job this many files', type=int, default=1)
@click.option('--debug/--no-debug', help='Debug mode for the job submission', default=False)
@click.option('--batch', default="bsub", type=click.Choice(["bsub", "htcondor"]),
              help='Select the job submission system to use')
@click_log.simple_verbosity_option(logger)
def run(config_file, debug, batch, files_per_job):
    # Read the config file
    config = ConfigParser()
    config.read(config_file)

    # Get the list of input files
    input_ntuples = config.get('input', 'files')
    input_ntuples = prepare_input_file_groups(input_ntuples, files_per_job)

    # Get the output directory
    output_directory = config.get('output', 'folder')
    batch_dir = os.path.join(output_directory, "batch")
    batch_dir = get_unique_out_dir(batch_dir)
    batch_config_dir = os.path.join(batch_dir, "_configs")
    logger.info("Batch config files will be placed under: " + batch_config_dir)
    os.makedirs(batch_config_dir)

    # Sort out a name for the batch config files
    n_jobs = len(input_ntuples)
    n_jobs_pad_width = int(math.log10(n_jobs)) + 1
    batch_filename = os.path.basename(config_file.name)
    batch_filename = list(os.path.splitext(batch_filename))
    batch_filename.insert(1, "_{index}")
    batch_filename = "".join(batch_filename)
    batch_filename = os.path.join(batch_config_dir, batch_filename)

    out_dir = "job_{index}"
    out_dir = os.path.join(batch_dir, out_dir)

    padding = "{{:0{}}}".format(n_jobs_pad_width)

    # Prepare input jobs
    job_configs = []
    for i, in_files in enumerate(input_ntuples):
        padded_index = padding.format(i)

        # Reset the input file list
        config.config['input']['files'] = in_files

        # Reset the output directory
        config.config['output']['folder'] = out_dir.format(index=padded_index)

        # Dump the config file
        batch_file = batch_filename.format(index=padded_index)
        config.dump(batch_file)

        job_configs.append(batch_file)

    # Now actually submit the jobs
    if batch == "bsub":
        submitter = cmsl1t_batch_job_bsub(batch_dir, debug)
    elif batch == "htcondor":
        submitter = cmsl1t_batch_job_htcondor(batch_dir, debug)
    result = submitter.submit(job_configs)

    if not all(result):
        logger.error("Error: submitting jobs failed...")
        return False

    # Finally dump the commands needed to run the next steps to screen:
    next_steps = """
    when all jobs are done, you can combine all results together with:

        cmsl1t -c {cfg} -r --hist-files '{out_dir}/*.root'

    ie. use the same config file given here, but reload hists from the intermediate root files.
    """

    logger.info(next_steps.format(cfg=config_file.name,
                                  out_dir=out_dir.format(index="*")))
    create_info_file(batch_dir)
    return True


if __name__ == '__main__':
    run()

